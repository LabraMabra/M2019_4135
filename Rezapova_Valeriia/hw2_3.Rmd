---
title: "Homework 2.3"
author: "Valeriia"
date: "20 05 2020"
output:
  html_document:
    df_print: paged
---
Load all needed libraries.
```{r message=F, warning=F}
library(MASS)
library(data.table)
library(ggplot2)
library(caret)
library(boot)
library(corrplot)
data(Boston)
```

Check our data. It's ok.
```{r}
bos <- Boston
str(bos)
dim(bos)
sum(is.na(bos))
summary(bos)
sum(duplicated(bos))
```

Charles River dummy variable (= 1 if tract bounds river; 0 otherwise). Drop it.
Check correlation. 

```{r}
corrplot(cor(bos, method = "spearman"), method = "number", type = "upper", diag = FALSE)
p.mat <- cor.mtest(bos)$p
corrplot(cor(bos, method = "spearman"), p.mat = p.mat, insig = "p-value", sig.level = -1)
```

Cathecorize data.

```{r}
bos <- data.table(bos)
bos[,medv_F:= cut(medv,c(0,quantile(bos$medv, 0.33),quantile(bos$medv, 0.66), 
                         max(bos$medv)),labels=c("1","2","3"))]
bos[,table(medv_F)]
```

PCA.
```{r}
library(pca3d)
pca <- prcomp(bos[,-c(13,14, 15)], center = TRUE, scale. = TRUE)

pca3d(pca, group=bos$medv_F)

dfdf = stats:::summary.prcomp(pca)$importance[2, ]

dtp <- data.frame('medv_F' = bos$medv_F, pca$x[,1:2])


ggplot(data = dtp) + 
       geom_point(aes(x = PC1, y = PC2, col = medv_F))+
  xlab(paste0("PC1 ", dfdf[1]*100))+
  ylab(paste0("PC2 ", dfdf[2]*100))
```

KNN. 
```{r}
set.seed(3)
intrain <- createDataPartition(y = bos$medv_F, p= 0.8, list = FALSE)
training <- bos[intrain,-13]
testing <- bos[-intrain,-13]
# Repeat several times, 10 blocks, 3 times
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)

knn_fit <- train(medv_F ~ ., data = training, method = "knn",
 trControl=trctrl,
 preProcess = c("center", "scale"), #normalisation
 tuneLength = 20) #K number
knn_fit
# The hieghest accuracy is in k=7
plot(knn_fit)

test_pred <- predict(knn_fit, newdata =testing)
head(data.frame(test_pred, testing$medv_F))
table(test_pred, Real = testing$medv_F)

knn_fit <- knn3Train(train = training[,-13], test = testing[,-13], k=7, cl = training$medv_F)
xtab <- table(knn_fit, Real = testing$medv_F)
xtab

accuracy = sum(knn_fit == testing$medv_F)/length(testing$medv_F)
precision = xtab[1,1]/sum(xtab[,1])
recall = xtab[1,1]/sum(xtab[1,])
f = 2 * (precision * recall) / (precision + recall)

#Accuracy - Accuracy is the most intuitive performance measure and it 
#is simply a ratio of correctly predicted observation to the total observations. (TP+TN)/(FP+FN+TP+TN)

paste0("Accuracy:", accuracy)

#Precision - Precision is the ratio of correctly predicted 
#positive observations to the total predicted positive observations. TP/(TP+FP)

paste0("Precision:", precision)

#Recall (Sensitivity) - Recall is the ratio of correctly predicted positive 
#observations to the all observations in actual class - yes. TP/(TP+FN)

paste0("Recall:", recall)

#F1 Score = 2*(Recall * Precision) / (Recall + Precision)

paste0("F:", f)
```
Polynomial regression

```{r warning=F, message=F}
ggplot(Boston,aes(lstat,medv))+geom_point()+geom_smooth()
bos[,medv_B:= cut(medv,c(0,median(bos$medv),max(bos$medv)),labels=c("low","high"))]
bos[,table(medv_B)]
set.seed(3)
bos1 <- bos[,-c(14,15)]
intrain <- createDataPartition(y = bos1$medv_B, p= 0.8, list = FALSE)
training <- bos[intrain,]
testing <- bos[-intrain,]
#k-fold CV
errors <- c()
for (i in 1:5){
  g <- glm(medv_B ~ poly(lstat,i), family = "binomial", data = bos1)
  errors[i] <- cv.glm(bos1, g)$delta[1]
}
plot(x = 1:5, y = errors, xlab = 'Polynomial degree', ylab = 'Cross-validation')

mod <- glm(medv_B ~ poly(lstat, 2), data = bos1, family = "binomial")
summary(mod)
```

```{r}
pred <- predict(mod, type = 'response') > 0.5
table(pred, Real = bos1$medv_B)
paste0("Accuracy:",sum(knn_fit == bos1$medv_B)/length(bos1$medv_B))
mod2 <- glm(medv_B ~ lstat, data = testing, family = "binomial")
summary(mod2)
pred2 <- predict(mod2, type = 'response', newdata = testing) > 0.5
table(pred2, Real = testing$medv_B)
paste0("Accuracy:",sum(knn_fit == testing$medv_B)/length(testing$medv_B))
```