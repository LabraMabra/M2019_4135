---
title: "HW2_2"
author: "Maria Firulyova"
output: html_document
---

```{r, echo=F}
knitr::opts_chunk$set(fig.width=12, fig.height=8, warning = F, message = F) 
```

```{r, warning=F, message=F}
library(data.table)
library(dplyr)
library(magrittr)
library(ggplot2)
library(tidyr)
library(plyr)
```

Load data, remove NA, transform some character variables to factor

```{r}
set.seed(1)
air_q <- fread('~/Загрузки/AirQualityUCI.csv', dec=',') %>% select(-c('V16', 'V17'))
air_q <- air_q %>%
  mutate(Date = as.factor(Date)) %>% 
  mutate(Time = as.factor(Time))
air_q <- sapply(select_if(air_q, is.numeric),
                function(x) ifelse (x < 0, NA, x)) %>%
  as.data.frame() %>% 
  drop_na()

air_q_long <- air_q %>% melt()
```

Heatmap: spearman correlations

```{r}
get_upper_tri <- function(cormat){
  cormat[lower.tri(cormat)]<- NA
  cormat
}

reorder_cormat <- function(cormat){
  dd <- as.dist((1-cormat)/2)
  hc <- hclust(dd)
  cormat <-cormat[hc$order, hc$order]
}

cor_mat <- cor(air_q, use = "complete.obs", method = "spearman")
cor_mat <- reorder_cormat(cor_mat)
upper_tri <- get_upper_tri(cor_mat)
melted_cormat <- melt(upper_tri, na.rm = TRUE) %>% mutate(value = round(value, 3))
ggheatmap <- ggplot(melted_cormat, aes(Var2, Var1, fill = value))+
  geom_tile(color = "white")+
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman\nCorrelation") +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1))+
  coord_fixed()
ggheatmap+
  geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.major = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.ticks = element_blank(),
    legend.justification = c(1, 0),
    legend.position = c(0.6, 0.7),
    legend.direction = "horizontal")+
  guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
                               title.position = "top", title.hjust = 0.5))

```

Since multicollinearity is a problem for linear regression, I remove some variables which correlated with the remained predictors. For this purpose, I use VIF criterion. The greater the VIF value, the stronger correlation is presented in the data. My *smart_model* function removes predictors until VIF will be < 5 

Also, my *x* variable will be *CO(GT)*

```{r}
set.seed(1)

VIF <- function(data)
{
  sapply(names(data[-1]), function(name) {
    m = lm(as.formula(paste(name, "~ .")), data[-1])
    r2 = summary(m)$r.squared
    1 / (1 - r2)})
}

smart_model <- function(data) {
  vif_data <- sort(VIF(data), decreasing = T)
  while (sum(vif_data > 5) != 0) {
    remove <- names(vif_data)[1]
    data <- data[ , !(names(data) %in% remove)]
    vif_data <- sort(VIF(data), decreasing = T)
  }
  fit <- lm(data[,1] ~ ., data[-1])
}

```

Perform linear regression

```{r}
set.seed(1)
colnames(air_q) <- colnames(air_q) %>% stringr::str_replace_all("\\(|\\)|\\.", "")
fit1 <- smart_model(air_q)
summary(fit1)
```

All selected variables are statistically significant, and adjusted R-squared is high.

What if I transform my variables? For example, log-transformation usually leads to more linear relationships between variables, and also interpretable, which is really useful not only for prediction aims, but also for results interpretation.

Also, log-transformation can remvoe heteroscedastisity.

```{r}
set.seed(1)
log_air <- apply(air_q, 2, log10) %>% as.data.frame()
fit2 <- smart_model(log_air)
summary(fit2)
```

The adjusted R-squared of model which based on transformed data are bigger than the previous one.

Let's use base *step* function for model selection (it's based on AIC scores and it's purpose is to find optimal number of predictors (the smaller the better) which describe the variance)

```{r}
set.seed(1)
optimal_fit <- step(lm(COGT ~ ., air_q), direction = 'backward')
summary(optimal_fit)
```

Let's investigate some quality metrics of builded model. I write *hetero_test* function which test whether there is heteroscedasticity in the builded model or not

```{r}
hetero_test <-  function(fit, df){
  fit_2 <- lm(fit$residuals^2 ~., df[-1])
  summary(fit_2)
}

explore_model <- function(fit, df) {
  vals <- cbind(fit$residuals, fit$fitted.values) %>% as.data.frame()  %>% magrittr::set_colnames(c('residuals', 'fitted'))
  cols <- names(fit$coefficients)[2:length(fit$coefficients)]
  het_res <- hetero_test(fit, df %>%
                           select(cols))
  ggplot(vals, aes(x = residuals, y = fitted))+
    geom_point()+
    theme_bw()+
    ggtitle(sprintf('shapiro p-value: %f, r^2 lm(fit$residuals^2 ~ ., df): %f', shapiro.test(fit$residuals)$p.value, het_res$r.squared))
}
```

**1.1** fit1: COGT ~ NMHCGT + PT08S3NOx + NO2GT + T + AH
```{r}
set.seed(1)
explore_model(fit1, air_q)
plot(fit1, which= c(1, 2))
```


**1.2** fit2: log10(COGT) ~ log10(NMHCGT) + log10(PT08S3NOx) + log10(NO2GT) + log10(T) + log10(AH)

```{r}
set.seed(1)
explore_model(fit2, log_air)
plot(fit2, which= c(1, 2))
```

**1.3** fit3:

```{r}
set.seed(1)
explore_model(optimal_fit, air_q)
plot(optimal_fit, which= c(1, 2))
```


I guess, the second model (log-transformation -> VIF selection) is the better than the *fit1* (VIF selection)  and *optimal_fit* (step result) because it has smaller extent of heteroscedastisity (however it is still a problem, and residuals are not normally distributed).